# Execution Plan: Test Coverage Audit
# Parent Task: rustgram-client-ma0.3 "Phase 3: Test Coverage Audit"
# Task ID: rustgram-client-dvx
# Generated: 2025-01-17

plan:
  title: "Test Coverage Audit for 396 Crates"
  complexity: HIGH
  estimated_batches: 15
  module_type: "Audit/Analysis"

  scope:
    total_crates: 396
    crates_with_unit_tests: 565  # Files with #[cfg(test)]
    crates_with_integration_tests: 4  # Files in tests/ directories
    critical_modules: 50
    manager_modules: 100
    type_modules: 200
    stub_modules: 46

  batch_strategy:
    batch_size: 25-30
    total_batches: 15
    parallel_batches: 3  # Can run 3 batches simultaneously

  tools:
    primary:
      - name: "cargo-llvm-cov"
        version: "0.6"
        purpose: "Code coverage reporting"
        command: "cargo llvm-cov --workspace --html --output-dir coverage"

    secondary:
      - name: "tarpaulin"
        version: "0.27"
        purpose: "Alternative coverage verification"
        command: "cargo tarpaulin --workspace --out Html"

    auxiliary:
      - name: "cargo test"
        purpose: "Run all tests"
        command: "cargo test --workspace"

      - name: "custom audit script"
        purpose: "Batch processing and aggregation"
        path: "tools/audit-test-coverage.sh"

  execution_steps:
    - id: 1
      name: "Inventory all crates"
      agent: "agent-analyst"
      description: |
        Create a complete inventory of all 396 crates, categorizing them by:
        - Critical modules (network, crypto, storage, auth)
        - Manager modules (business logic)
        - Type modules (simple enums/structs)
        - Stub modules (placeholder implementations)
      depends_on: []
      acceptance:
        - "Complete crate inventory with categorization"
        - "Dependency graph for critical modules"
        - "Test status for each crate (tested/untested)"

    - id: 2
      name: "Audit critical modules (Batch 1-5)"
      agent: "agent-analyst"
      description: |
        Audit the 50 critical modules in batches of 10:
        Batch 1: net, crypto, actor, storage, auth_manager, password_manager
        Batch 2: dialog_manager, message_db, user_manager, chat_manager, call_manager
        Batch 3: connection_state_manager, request_actor, client_actor, td_json_client, td_c_client
        Batch 4: file_uploader, file_downloader, download_manager, upload_manager, parts_manager
        Batch 5: notifications_manager, updates_manager, messages_manager, secret_chat_actor, call_actor
      depends_on: [1]
      parallel_group: 1
      acceptance:
        - "Coverage report for all critical modules"
        - "List of untested critical functions"
        - "Actor message passing test validation"

    - id: 3
      name: "Audit manager modules (Batch 6-10)"
      agent: "agent-analyst"
      description: |
        Audit 100 manager modules in batches of 20:
        Batch 6-10: All *_manager crates excluding those already audited
      depends_on: [1]
      parallel_group: 1
      acceptance:
        - "Coverage report for all manager modules"
        - "List of untested manager logic"
        - "Integration test recommendations"

    - id: 4
      name: "Audit type modules (Batch 11-13)"
      agent: "agent-analyst"
      description: |
        Audit 200 type modules (simple wrappers, enums) in batches of 70:
        Batch 11: user_id, chat_id, message_id, dialog_id, etc.
        Batch 12: Type enums and simple structs
        Batch 13: Remaining type modules
      depends_on: [1]
      parallel_group: 1
      acceptance:
        - "Coverage report for type modules"
        - "List of completely untested types"

    - id: 5
      name: "Audit stub modules (Batch 14-15)"
      agent: "agent-analyst"
      description: |
        Audit 46 stub modules (placeholder implementations) in batches of 23.
        These have minimal test requirements.
      depends_on: [1]
      parallel_group: 1
      acceptance:
        - "Basic validation test status for stubs"
        - "List of stubs needing any tests"

    - id: 6
      name: "Validate actor message passing tests"
      agent: "agent-analyst"
      description: |
        Specifically validate actor message passing tests:
        1. Check ActorId<T> type safety tests
        2. Verify ActorShared<T> clone behavior
        3. Test NetActor trait implementations
        4. Validate message callback patterns
        5. Check concurrent message handling
      depends_on: [2]
      acceptance:
        - "Actor framework test coverage report"
        - "Message passing test validation results"
        - "Recommendations for actor testing improvements"

    - id: 7
      name: "Generate aggregate coverage report"
      agent: "agent-analyst"
      description: |
        Combine all batch reports into a comprehensive coverage report:
        1. Overall coverage percentage
        2. Coverage by category (critical, manager, type, stub)
        3. List of completely untested crates
        4. List of crates below coverage threshold
        5. Recommendations for test additions
      depends_on: [2, 3, 4, 5, 6]
      acceptance:
        - "Comprehensive coverage report"
        - "Prioritized list of crates needing tests"
        - "Test coverage by module category"

    - id: 8
      name: "Identify untested critical modules"
      agent: "agent-analyst"
      description: |
        From the coverage report, identify critical modules that are:
        1. Completely untested (0% coverage)
        2. Below 70% coverage threshold
        3. Missing tests for critical paths
      depends_on: [7]
      acceptance:
        - "List of untested critical modules"
        - "Gap analysis for each module"
        - "Prioritized recommendations"

    - id: 9
      name: "Create test implementation roadmap"
      agent: "agent-analyst"
      description: |
        Based on the audit results, create a roadmap for implementing missing tests:
        1. Prioritize by criticality
        2. Estimate effort for each module
        3. Identify dependencies
        4. Create implementation batches
      depends_on: [8]
      acceptance:
        - "Test implementation roadmap"
        - "Effort estimates for each module"
        - "Dependencies identified"

    - id: 10
      name: "Document findings and recommendations"
      agent: "agent-docs"
      description: |
        Create final documentation:
        1. Audit summary report
        2. Coverage visualization
        3. Testing recommendations
        4. Tool configuration guide
      depends_on: [9]
      acceptance:
        - "Complete audit report"
        - "Coverage visualizations"
        - "Actionable recommendations"

  dependencies:
    external:
      - tool: "cargo-llvm-cov"
        required: true
        install: "cargo install cargo-llvm-cov"

      - tool: "tarpaulin"
        required: false
        install: "cargo install cargo-tarpaulin"

    internal:
      - "Complete crate inventory"
      - "Existing test files identified"
      - "Critical module list"

  testing_strategy:
    audit_methodology:
      phase1_inventory:
        tool: "custom script"
        output: "crate-inventory.json"

      phase2_coverage:
        tool: "cargo-llvm-cov"
        batches: 15
        batch_size: 25-30
        output: "coverage-reports/"

      phase3_validation:
        tool: "manual review + custom checks"
        focus: "actor message passing"

      phase4_reporting:
        tool: "custom aggregation script"
        output: "audit-report.md"

    coverage_thresholds:
      critical: 70
      manager: 60
      type: 50
      stub: 20

  risk_mitigation:
    - risk: "Large workspace may cause memory issues with coverage tools"
      mitigation: "Use batch processing, limit to 25-30 crates per batch"
      priority: "high"

    - risk: "Coverage tool conflicts with workspace features"
      mitigation: "Test with both cargo-llvm-cov and tarpaulin"
      priority: "medium"

    - risk: "Actor message passing tests may be inadequate"
      mitigation: "Dedicated validation step for actor framework"
      priority: "high"

    - risk: "Some crates may not compile in isolation"
      mitigation: "Use workspace-level testing, note compilation issues"
      priority: "medium"
